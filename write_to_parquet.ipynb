{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import zstandard as zstd\n",
    "from torch import Tensor\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from dataloader import XPlaneVideoDataset\n",
    "from utils import frame2bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = pa.schema([\n",
    "    (\"video_name\", pa.string()),\n",
    "    (\"frame_bytes\", pa.binary()),\n",
    "    (\"frame_id\", pa.int64()),\n",
    "    (\"sim_time\", pa.float64()),\n",
    "    (\"state\", pa.list_(pa.float64(), 11)),\n",
    "    (\"time_of_day\", pa.string()),\n",
    "    (\"time_since_midnight\", pa.float64()),\n",
    "    (\"weather_cloud_cover\", pa.list_(pa.float64(), 3)),\n",
    "    (\"weather_cloud_type\", pa.list_(pa.float64(), 3)),\n",
    "    (\"weather_rain_snow_none\", pa.string()),\n",
    "    (\"weather_rain_percent\", pa.float64()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55719e1d6ec0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55719866cd00] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55719e1d6ec0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55719ea08600] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55719de3f280] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55719e1d6ec0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55719e1d6ec0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55719e2f4dc0] moov atom not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing XPlaneVideoDataset.\n"
     ]
    }
   ],
   "source": [
    "#transform = T.Compose([T.Lambda(lambda x: x.transpose(-1, -3)), T.Resize((360, 640))])\n",
    "transform = T.Compose([T.Lambda(lambda x: x.permute((2, 0, 1)))])\n",
    "ds = XPlaneVideoDataset(\n",
    "    Path(\"~/datasets/xplane_recording\").expanduser(), output_full_data=True, transform=transform\n",
    ")\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    frame, data, weather = zip(*batch)\n",
    "    mask = [\n",
    "        f is not None and d is not None and w is not None for (f, d, w) in zip(frame, data, weather)\n",
    "    ]\n",
    "    frame = [f for (f, m) in zip(frame, mask) if m]\n",
    "    data = [d for (d, m) in zip(data, mask) if m]\n",
    "    weather = [w for (w, m) in zip(weather, mask) if m]\n",
    "    frames = [frame2bytes(f) for f in frame]\n",
    "    data = {k: [d[k] for d in data] for k in data[0].keys()}\n",
    "    weather = {k: [w[k] for w in weather] for k in weather[0].keys()}\n",
    "    return frames, data, weather\n",
    "\n",
    "\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=128, collate_fn=custom_collate_fn, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1949 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/rdyro/.pyenv/versions/devel/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 1949/1949 [29:43<00:00,  1.09it/s] \n"
     ]
    }
   ],
   "source": [
    "db_file = Path(\"/mnt/Storage2/xplane_dataset_gs1.parquet\")\n",
    "writer = pq.ParquetWriter(db_file, schema)\n",
    "try:\n",
    "    for frames, datas, weathers in tqdm(dl, total=len(dl)):\n",
    "        df = pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"video_name\": datas[\"video_name\"],\n",
    "                \"frame_bytes\": frames,\n",
    "                \"frame_id\": datas[\"frame_id\"],\n",
    "                \"sim_time\": datas[\"sim_time\"],\n",
    "                \"state\": datas[\"state\"],\n",
    "                \"time_of_day\": weathers[\"time_of_day\"],\n",
    "                \"time_since_midnight\": weathers[\"time_since_midnight\"],\n",
    "                \"weather_cloud_cover\": weathers[\"cloud_cover\"],\n",
    "                \"weather_cloud_type\": weathers[\"cloud_type\"],\n",
    "                \"weather_rain_snow_none\": weathers[\"rain_snow_none\"],\n",
    "                \"weather_rain_percent\": weathers[\"rain_percent\"],\n",
    "            }\n",
    "        )\n",
    "        datum = pa.Table.from_pandas(df, schema=schema)\n",
    "        writer.write_table(datum, row_group_size=1)\n",
    "finally:\n",
    "    writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = Path(\"~/datasets/xplane_datset.parquet\").expanduser()\n",
    "reader = pq.ParquetFile(db_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parquet_dataloader import ParquetXPlaneVideoDataset, ParquetXPlaneVideoDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = ParquetXPlaneVideoDataset(db_file, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1722e-03 s\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "t = time.time()\n",
    "for _ in range(1000):\n",
    "    idx = random.randint(0, 249438 - 1)\n",
    "    a = ds2[idx]\n",
    "print(f\"{(time.time() - t) / 1e3:.4e} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl2 = ParquetXPlaneVideoDataLoader(db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0520e-01 s\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "for _ in range(100):\n",
    "    ridx = random.randint(0, 249438 - 200)\n",
    "    X, y = dl2.get_range(ridx, ridx + 128)\n",
    "print(f\"{(time.time() - t) / 100:.4e} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x560b93e7dac0] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x560b8dc57e40] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x560b93e93140] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x560b93ea8880] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x560b8e419440] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x560b8e419440] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x560b8e419440] moov atom not found\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x560b93edeb40] moov atom not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done initializing XPlaneVideoDataset.\n",
      "4.2104e-01 s\n"
     ]
    }
   ],
   "source": [
    "ds = XPlaneVideoDataset(Path(\"~/datasets/xplane_recording\").expanduser(), transform=None)\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    frames, states = zip(*batch)\n",
    "    mask = [f is not None and s is not None for (f, s) in zip(frames, states)]\n",
    "    frames = [f for (f, m) in zip(frames, mask) if m]\n",
    "    states = [s for (s, m) in zip(states, mask) if m]\n",
    "    return torch.stack(frames), torch.stack(states).to(torch.float32)\n",
    "\n",
    "\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    ds, batch_size=128, collate_fn=custom_collate_fn, num_workers=8, shuffle=True\n",
    ")\n",
    "it = iter(dl)\n",
    "t = time.time()\n",
    "for _ in range(100):\n",
    "    batch = next(it)\n",
    "print(f\"{(time.time() - t) / 100:.4e} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
